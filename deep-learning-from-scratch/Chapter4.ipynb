{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2乗和誤差（MSE: Mean Squared Error）は下記の式から導出される\n",
    "$$ E = \\frac{1}{2}\\displaystyle\\sum_k (y_k - t_k)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def mean_squared_error(y,t):\n",
    "    return 0.5 * np.sum((y-t)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.097500000000000031"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [0,0,1,0,0,0,0,0,0,0]\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0,0.1,0.0,0.0]\n",
    "mean_squared_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59750000000000003"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [0.1, 0.05, 0.1,0.0,0.05,0.1,0.0,0.6,0.0,0.0]\n",
    "mean_squared_error(np.array(y),np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一方、交差エントロピー誤差（Cross Entropy Error）は下記の式から導出される\n",
    "$$ E = -\\sum_k t_k\\log y_k $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t*np.log(y+delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51082545709933802"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [0,0,1,0,0,0,0,0,0,0]\n",
    "y = [0.1,0.05,0.6,0.0,0.05,0.1,0.0,0.1,0.0,0.0]\n",
    "cross_entropy_error(np.array(y),np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3025840929945458"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [0.1, 0.05,0.1,0.0,0.05,0.1,0.0,0.6,0.0,0.0]\n",
    "cross_entropy_error(np.array(y),np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting train-images-idx3-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting train-labels-idx1-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting t10k-images-idx3-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting t10k-labels-idx1-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Creating pickle file ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "try:\n",
    "    import urllib.request\n",
    "except ImportError:\n",
    "    raise ImportError('You should use Python 3.x')\n",
    "import os.path\n",
    "import gzip\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "url_base = 'http://yann.lecun.com/exdb/mnist/'\n",
    "key_file = {\n",
    "    'train_img':'train-images-idx3-ubyte.gz',\n",
    "    'train_label':'train-labels-idx1-ubyte.gz',\n",
    "    'test_img':'t10k-images-idx3-ubyte.gz',\n",
    "    'test_label':'t10k-labels-idx1-ubyte.gz'\n",
    "}\n",
    "\n",
    "dataset_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "save_file = dataset_dir + \"/mnist.pkl\"\n",
    "\n",
    "train_num = 60000\n",
    "test_num = 10000\n",
    "img_dim = (1, 28, 28)\n",
    "img_size = 784\n",
    "\n",
    "\n",
    "def _download(file_name):\n",
    "    file_path = dataset_dir + \"/\" + file_name\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        return\n",
    "\n",
    "    print(\"Downloading \" + file_name + \" ... \")\n",
    "    urllib.request.urlretrieve(url_base + file_name, file_path)\n",
    "    print(\"Done\")\n",
    "    \n",
    "def download_mnist():\n",
    "    for v in key_file.values():\n",
    "       _download(v)\n",
    "        \n",
    "def _load_label(file_name):\n",
    "    file_path = dataset_dir + \"/\" + file_name\n",
    "    \n",
    "    print(\"Converting \" + file_name + \" to NumPy Array ...\")\n",
    "    with gzip.open(file_path, 'rb') as f:\n",
    "            labels = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "    print(\"Done\")\n",
    "    \n",
    "    return labels\n",
    "\n",
    "def _load_img(file_name):\n",
    "    file_path = dataset_dir + \"/\" + file_name\n",
    "    \n",
    "    print(\"Converting \" + file_name + \" to NumPy Array ...\")    \n",
    "    with gzip.open(file_path, 'rb') as f:\n",
    "            data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "    data = data.reshape(-1, img_size)\n",
    "    print(\"Done\")\n",
    "    \n",
    "    return data\n",
    "    \n",
    "def _convert_numpy():\n",
    "    dataset = {}\n",
    "    dataset['train_img'] =  _load_img(key_file['train_img'])\n",
    "    dataset['train_label'] = _load_label(key_file['train_label'])    \n",
    "    dataset['test_img'] = _load_img(key_file['test_img'])\n",
    "    dataset['test_label'] = _load_label(key_file['test_label'])\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def init_mnist():\n",
    "    download_mnist()\n",
    "    dataset = _convert_numpy()\n",
    "    print(\"Creating pickle file ...\")\n",
    "    with open(save_file, 'wb') as f:\n",
    "        pickle.dump(dataset, f, -1)\n",
    "    print(\"Done!\")\n",
    "\n",
    "def _change_ont_hot_label(X):\n",
    "    T = np.zeros((X.size, 10))\n",
    "    for idx, row in enumerate(T):\n",
    "        row[X[idx]] = 1\n",
    "        \n",
    "    return T\n",
    "    \n",
    "\n",
    "def load_mnist(normalize=True, flatten=True, one_hot_label=False):\n",
    "    \"\"\"MNISTデータセットの読み込み\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    normalize : 画像のピクセル値を0.0~1.0に正規化する\n",
    "    one_hot_label : \n",
    "        one_hot_labelがTrueの場合、ラベルはone-hot配列として返す\n",
    "        one-hot配列とは、たとえば[0,0,1,0,0,0,0,0,0,0]のような配列\n",
    "    flatten : 画像を一次元配列に平にするかどうか \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    (訓練画像, 訓練ラベル), (テスト画像, テストラベル)\n",
    "    \"\"\"\n",
    "    if not os.path.exists(save_file):\n",
    "        init_mnist()\n",
    "        \n",
    "    with open(save_file, 'rb') as f:\n",
    "        dataset = pickle.load(f)\n",
    "    \n",
    "    if normalize:\n",
    "        for key in ('train_img', 'test_img'):\n",
    "            dataset[key] = dataset[key].astype(np.float32)\n",
    "            dataset[key] /= 255.0\n",
    "            \n",
    "    if one_hot_label:\n",
    "        dataset['train_label'] = _change_ont_hot_label(dataset['train_label'])\n",
    "        dataset['test_label'] = _change_ont_hot_label(dataset['test_label'])    \n",
    "    \n",
    "    if not flatten:\n",
    "         for key in ('train_img', 'test_img'):\n",
    "            dataset[key] = dataset[key].reshape(-1, 1, 28, 28)\n",
    "\n",
    "    return (dataset['train_img'], dataset['train_label']), (dataset['test_img'], dataset['test_label']) \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    init_mnist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_mask values are: [45560 19626 42097 38295 31882 34181 46912 10637 26141 36674]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([50599, 35717, 20247, 10543, 48451, 26458,  2860, 25904, 44470,  5262])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size)\n",
    "print(\"batch_mask values are: %s\" % batch_mask)\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]\n",
    "np.random.choice(60000,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_entropy_error(y,t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1,t.size)\n",
    "        y = y.reshape(1,y.size)\n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(t*np.log(y)) / batch_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "教師データtがone-hot表現ではなく、ラベルで与えられた時の交差エントロピー誤差を計算するメソッドは次のようになる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def corss_entropy_error(y, t):\n",
    "    if y.din == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size)]))/batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数値微分の関数を定義する。ここではhを丸め誤差を考慮し$10^{-4}$とし、なおかつ$h$の前後の差分を用いて計算する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def numerical_diff(f,x):\n",
    "    h = 1e-4 # 0.0001\n",
    "    return (f(x+h) - f(x-h)) / (2*h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下記の式をPythonを用いて実装する\n",
    "$$y = 0.01x^2 + 0.1x$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def function_1(x):\n",
    "    return 0.01*x**2 + 0.1*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhEAAAF5CAYAAAAh0Xi4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b54d6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "x = np.arange(0.0,20.0,0.1)\n",
    "y = function_1(x)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1999999999990898"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_diff(function_1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2999999999986347"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_diff(function_1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一方下記のような２変数関数を考える"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f(x_0, x_1) = x_0^2 + x_1^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "勾配法は次式で表される\n",
    "$$x_0 = x_0 - \\eta \\frac{\\partial f}{\\partial x_0}$$\n",
    "$$x_1 = x_1 - \\eta \\frac{\\partial f}{\\partial x_1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
    "    x = init_x\n",
    "    \n",
    "    for i in range(step_num):\n",
    "        grad = numerical_gradient(f,x)\n",
    "        x -= lr * grad\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'common.functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-aea0bb817636>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpardir\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 親ディレクトリのファイルをインポートするための設定\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'common.functions'"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "from common.functions import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "\n",
    "class TwoLayerNet:\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        # 重みの初期化\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "    def predict(self, x):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "    \n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        return y\n",
    "        \n",
    "    # x:入力データ, t:教師データ\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        \n",
    "        return cross_entropy_error(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "        \n",
    "    # x:入力データ, t:教師データ\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads\n",
    "        \n",
    "    def gradient(self, x, t):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "        grads = {}\n",
    "        \n",
    "        batch_num = x.shape[0]\n",
    "        \n",
    "        # forward\n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        # backward\n",
    "        dy = (y - t) / batch_num\n",
    "        grads['W2'] = np.dot(z1.T, dy)\n",
    "        grads['b2'] = np.sum(dy, axis=0)\n",
    "        \n",
    "        da1 = np.dot(dy, W2.T)\n",
    "        dz1 = sigmoid_grad(a1) * da1\n",
    "        grads['W1'] = np.dot(x.T, dz1)\n",
    "        grads['b1'] = np.sum(dz1, axis=0)\n",
    "\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
